{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Análisis del Mercado Laboral Español (EPA)\n\nProyecto de análisis exploratorio de datos (EDA) sobre el mercado laboral español\nutilizando datos abiertos del Instituto Nacional de Estadística (INE) — Encuesta de Población Activa (EPA).\n\n## Objetivo\n\nEntender la estructura del mercado laboral español por provincia, sexo y sector económico,\nsu evolución trimestral, y las desigualdades territoriales y de género en empleo y desempleo.\n\n## Preguntas\n\n- **Q1:** ¿Cuáles son las provincias con mayor y menor tasa de paro? ¿Ha cambiado el ranking?\n- **Q2:** ¿Existe brecha de género en las tasas de actividad, empleo y paro? ¿Varía por provincia?\n- **Q3:** ¿Cómo se distribuye el empleo por sector económico (agricultura, industria, construcción, servicios) y cómo varía geográficamente?\n- **Q4:** ¿Cómo ha evolucionado el empleo total a lo largo del periodo?\n- **Q5:** ¿Existe estacionalidad en el empleo/paro (trimestral)? ¿Afecta más a unas provincias que a otras?\n- **Q6:** ¿Cómo varía la tasa de paro según el grupo de edad? ¿Qué diferencias hay por sexo?\n- **Q7:** ¿Cómo ha evolucionado el paro juvenil frente al total?\n- **Q8:** ¿Existe brecha de desempleo entre trabajadores españoles y extranjeros? ¿Varía según la edad?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport sys\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport seaborn as sns\n\nsns.set_theme(context='notebook', style='whitegrid')\npd.set_option('display.max_columns', 20)\npd.set_option('display.max_rows', 60)\n\n# Add project root to sys.path (notebook runs from notebooks/)\nsys.path.insert(0, str(Path.cwd().parent))\n\n# Import centralized paths from src/config.py\nfrom src.config import ROOT, DATA_RAW, DATA_PROCESSED, CHARTS_DIR, RAW_PATH, OUT_PATH\n\nCHARTS = CHARTS_DIR  # alias used throughout this notebook\nCHARTS.mkdir(parents=True, exist_ok=True)\n\n# Clean previous charts before generating new ones\nfor f in CHARTS.glob('*.png'):\n    f.unlink()\nprint('Limpiados graficos anteriores.')\n\ncsv_path = RAW_PATH\nprint(f'Project root: {ROOT}')\nprint(f'CSV path: {csv_path}')\nprint(f'Exists: {csv_path.exists()}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) QC Rapido\n",
    "\n",
    "Detectar problemas sin perder 30 minutos: `head()`, `shape`, `info()`, nulos, duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "display(df.head(10))\n",
    "print(f'\\nShape: {df.shape}')\n",
    "print(f'\\nInfo:')\n",
    "display(df.info())\n",
    "\n",
    "na_rate = (df.isna().mean().sort_values(ascending=False) * 100).round(2)\n",
    "dup_count = df.duplicated().sum()\n",
    "\n",
    "print(f'\\nMissing %:')\n",
    "display(na_rate)\n",
    "print(f'\\nDuplicated rows: {dup_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardinality & rare categories check\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f'Categorical columns: {cat_cols}\\n')\n",
    "\n",
    "for col in cat_cols:\n",
    "    nunique = df[col].nunique(dropna=True)\n",
    "    print(f'--- {col} --- (n_unique={nunique})')\n",
    "    display(df[col].value_counts(dropna=False).head(10))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problemas detectados\n",
    "\n",
    "| Problema | Detalle |\n",
    "|---|---|\n",
    "| Nombres de columna sucios | Espacios, mayusculas mezcladas (`' Valor'`, `'Fecha '`) |\n",
    "| Valor como texto | Mezcla de numeros con punto y coma decimal (`42315.3` vs `203,2`) |\n",
    "| Fechas en 5 formatos | `2024-06-30`, `30/06/2025`, `2025/03/31`, `Dec 31, 2024`, `1727733600000` (ms) |\n",
    "| Serie_nombre inconsistente | Mismo dato en mayusculas/minusculas, espacios extra |\n",
    "| ~3% de nulls en Valor | 1125 valores faltantes |\n",
    "| 20 filas duplicadas | Filas repetidas exactas |\n",
    "| Serie_nombre empaquetado | Todas las dimensiones (provincia, sexo, actividad) en un solo string |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# 2.1) Fix column names: strip, lowercase, underscores\n",
    "df_clean.columns = [c.strip().lower().replace(' ', '_') for c in df_clean.columns]\n",
    "print('Columns after fix:', df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2) Fix 'valor': replace commas with dots, convert to numeric\n",
    "df_clean['valor'] = (\n",
    "    df_clean['valor']\n",
    "    .astype('string')\n",
    "    .str.replace(',', '.', regex=False)\n",
    ")\n",
    "df_clean['valor'] = pd.to_numeric(df_clean['valor'], errors='coerce')\n",
    "print(f'valor dtype: {df_clean[\"valor\"].dtype}')\n",
    "print(f'valor nulls: {df_clean[\"valor\"].isna().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3) Fix 'serie_nombre': strip whitespace, normalize to title case\n",
    "df_clean['serie_nombre'] = (\n",
    "    df_clean['serie_nombre']\n",
    "    .astype('string')\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Normalize: all to the canonical form (first letter caps, rest lower)\n",
    "# We need to be careful with proper nouns and acronyms\n",
    "# Strategy: lowercase everything, then fix known patterns\n",
    "df_clean['serie_nombre_lower'] = df_clean['serie_nombre'].str.lower()\n",
    "\n",
    "# Check how many unique after lowercasing\n",
    "print(f'Unique serie_nombre (raw):   {df_clean[\"serie_nombre\"].nunique()}')\n",
    "print(f'Unique serie_nombre (lower): {df_clean[\"serie_nombre_lower\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2.4) Parse serie_nombre into structured columns\n# Patterns detected (all lowered for matching):\n#   Table 65345 national: \"total nacional. {sexo}. 16 y más años. {actividad}. personas.\"\n#   Table 65345 province: \"{sexo}. {provincia}. 16 y más años. {actividad}. personas.\"\n#   Table 65349: \"tasa de {tipo}. {provincia|ambos sexos}. {sexo|total nacional}. total.\"\n#   Table 65354: \"{provincia|total nacional}. ocupados. ambos sexos. {sector}. personas.\"\n\n# Build canonical province name mapping — prefer properly-cased (non-UPPER) names\nprovincia_canonical = {}\nfor nombre in df_clean[df_clean['tabla'] == 65345]['serie_nombre'].unique():\n    parts = [p.strip() for p in nombre.split('. ') if p.strip()]\n    if parts[0].lower() != 'total nacional' and len(parts) >= 4:\n        prov = parts[1]\n        key = prov.lower()\n        # Only overwrite if we don't have a canonical form yet, or the current one is ALL CAPS\n        if key not in provincia_canonical or provincia_canonical[key] == provincia_canonical[key].upper():\n            provincia_canonical[key] = prov\n\n# Manual fixes for provinces that may only appear uppercased\nprovincia_fixes = {\n    'albacete': 'Albacete', 'alicante/alacant': 'Alicante/Alacant',\n    'araba/álava': 'Araba/Álava', 'asturias': 'Asturias', 'badajoz': 'Badajoz',\n    'barcelona': 'Barcelona', 'burgos': 'Burgos', 'cantabria': 'Cantabria',\n    'castellón/castelló': 'Castellón/Castelló', 'ceuta': 'Ceuta',\n    'ciudad real': 'Ciudad Real', 'coruña, a': 'Coruña, A', 'cuenca': 'Cuenca',\n    'gipuzkoa': 'Gipuzkoa', 'girona': 'Girona', 'guadalajara': 'Guadalajara',\n    'lugo': 'Lugo', 'melilla': 'Melilla', 'murcia': 'Murcia',\n    'málaga': 'Málaga', 'navarra': 'Navarra', 'palmas, las': 'Palmas, Las',\n    'rioja, la': 'Rioja, La', 'salamanca': 'Salamanca', 'segovia': 'Segovia',\n    'teruel': 'Teruel', 'valencia/valència': 'Valencia/València',\n    'valladolid': 'Valladolid', 'zamora': 'Zamora', 'zaragoza': 'Zaragoza',\n}\nfor k, v in provincia_fixes.items():\n    if k not in provincia_canonical or provincia_canonical[k] == provincia_canonical[k].upper():\n        provincia_canonical[k] = v\n\nprovincia_canonical['total nacional'] = 'Total Nacional'\n\n# Canonical sexo mapping\nsexo_canonical = {'ambos sexos': 'Ambos sexos', 'hombres': 'Hombres', 'mujeres': 'Mujeres'}\n\ndef canon_prov(s):\n    return provincia_canonical.get(s.lower().strip(), s.strip().title())\n\ndef canon_sexo(s):\n    return sexo_canonical.get(s.lower().strip(), s.strip().title())\n\ndef parse_serie_65345(nombre_lower):\n    parts = [p.strip() for p in nombre_lower.split('. ') if p.strip()]\n    if parts[0] == 'total nacional':\n        return {'provincia': 'Total Nacional', 'sexo': canon_sexo(parts[1]), 'actividad': parts[3].title()}\n    else:\n        return {'provincia': canon_prov(parts[1]), 'sexo': canon_sexo(parts[0]), 'actividad': parts[3].title()}\n\ndef parse_serie_65349(nombre_lower):\n    parts = [p.strip() for p in nombre_lower.split('. ') if p.strip()]\n    tasa = next((p for p in parts if 'tasa' in p), 'desconocida')\n    tasa_display = tasa.replace('tasa de ', 'Tasa de ').replace('la población', 'la poblacion')\n    remaining = [p for p in parts if p != tasa and p not in ('total', 'total.', 'personas')]\n    provincia = 'Total Nacional'\n    sexo = 'Ambos sexos'\n    for r in remaining:\n        r_clean = r.rstrip('.')\n        if r_clean in ('ambos sexos', 'hombres', 'mujeres'):\n            sexo = canon_sexo(r_clean)\n        elif r_clean == 'total nacional':\n            provincia = 'Total Nacional'\n        elif r_clean not in ('total',):\n            provincia = canon_prov(r_clean)\n    return {'provincia': provincia, 'sexo': sexo, 'actividad': tasa_display}\n\ndef parse_serie_65354(nombre_lower):\n    parts = [p.strip() for p in nombre_lower.split('. ') if p.strip()]\n    provincia = canon_prov(parts[0]) if parts[0] != 'ocupados' else 'Total Nacional'\n    sector = 'Total'\n    for p in parts:\n        if p in ('agricultura', 'industria', 'construcción', 'servicios', 'total cnae'):\n            sector = p.title()\n            break\n    return {'provincia': provincia, 'sexo': 'Ambos sexos', 'actividad': f'Ocupados - {sector}'}\n\n# Apply parsing using lowered names\nrecords = []\nfor _, row in df_clean.iterrows():\n    nombre_lower = row['serie_nombre_lower']\n    tabla = row['tabla']\n    try:\n        if tabla == 65345:\n            parsed = parse_serie_65345(nombre_lower)\n        elif tabla == 65349:\n            parsed = parse_serie_65349(nombre_lower)\n        elif tabla == 65354:\n            parsed = parse_serie_65354(nombre_lower)\n        else:\n            parsed = {'provincia': 'Desconocida', 'sexo': 'Desconocido', 'actividad': 'Desconocida'}\n    except Exception:\n        parsed = {'provincia': 'Error', 'sexo': 'Error', 'actividad': 'Error'}\n    records.append(parsed)\n\ndf_parsed = pd.DataFrame(records)\ndf_clean = pd.concat([df_clean, df_parsed], axis=1)\n\nprint(f'New columns: {df_parsed.columns.tolist()}')\nprint(f'\\nProvincia unique: {df_clean[\"provincia\"].nunique()}')\nprint(f'Sexo unique: {df_clean[\"sexo\"].nunique()}')\nprint(f'Actividad unique: {df_clean[\"actividad\"].nunique()}')\nprint()\nprint('Provincias sample:')\ndisplay(df_clean['provincia'].value_counts().head(15))\nprint('\\nActividad values:')\ndisplay(df_clean['actividad'].value_counts())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2.5) Parse dates robustly\nfrom datetime import datetime\n\ndef parse_fecha(val):\n    \"\"\"Parse date from mixed formats: ISO, dd/mm/yyyy, yyyy/mm/dd, textual, ms timestamp.\"\"\"\n    if pd.isna(val) or val == '<NA>':\n        return pd.NaT\n    val = str(val).strip()\n    # Try ms timestamp first (pure digits, very long)\n    if val.isdigit() and len(val) > 10:\n        try:\n            return pd.Timestamp(int(val), unit='ms')\n        except Exception:\n            pass\n    # Try standard formats\n    for fmt in ['%Y-%m-%d', '%d/%m/%Y', '%Y/%m/%d', '%b %d, %Y']:\n        try:\n            return pd.Timestamp(datetime.strptime(val, fmt))\n        except (ValueError, AttributeError):\n            continue\n    # Fallback\n    try:\n        return pd.to_datetime(val, dayfirst=True)\n    except Exception:\n        return pd.NaT\n\n# Build a Series from parsed values and convert to datetime (satisfies type-checkers)\nparsed = [parse_fecha(x) for x in df_clean['fecha']]\ndf_clean['fecha'] = pd.to_datetime(pd.Series(parsed))\nprint(f'fecha dtype: {df_clean[\"fecha\"].dtype}')\nprint(f'fecha nulls: {df_clean[\"fecha\"].isna().sum()}')\nprint(f'fecha range: {df_clean[\"fecha\"].min()} to {df_clean[\"fecha\"].max()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6) Normalize categorical values\n",
    "\n",
    "# Normalize sexo\n",
    "sexo_map = {\n",
    "    'ambos sexos': 'Ambos sexos',\n",
    "    'hombres': 'Hombres',\n",
    "    'mujeres': 'Mujeres',\n",
    "    'AMBOS SEXOS': 'Ambos sexos',\n",
    "    'HOMBRES': 'Hombres',\n",
    "    'MUJERES': 'Mujeres',\n",
    "}\n",
    "df_clean['sexo'] = df_clean['sexo'].str.strip().replace(sexo_map)\n",
    "\n",
    "# Normalize provincia\n",
    "df_clean['provincia'] = df_clean['provincia'].str.strip()\n",
    "\n",
    "# Normalize actividad\n",
    "df_clean['actividad'] = df_clean['actividad'].str.strip()\n",
    "\n",
    "print('Sexo values:')\n",
    "display(df_clean['sexo'].value_counts())\n",
    "print('\\nProvincia (top 10):')\n",
    "display(df_clean['provincia'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7) Drop duplicates\n",
    "print(f'Before dedup: {df_clean.shape[0]}')\n",
    "df_clean = df_clean.drop_duplicates(subset=['tabla', 'serie_cod', 'anyo', 'periodo_id'])\n",
    "print(f'After dedup:  {df_clean.shape[0]}')\n",
    "\n",
    "# 2.8) Drop helper columns\n",
    "df_clean = df_clean.drop(columns=['serie_nombre_lower', 'secreto'], errors='ignore')\n",
    "\n",
    "print(f'\\nFinal clean shape: {df_clean.shape}')\n",
    "print(f'Columns: {df_clean.columns.tolist()}')\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Validation asserts\nassert df_clean.duplicated(subset=['tabla', 'serie_cod', 'anyo', 'periodo_id']).sum() == 0, 'Duplicates remain!'\nassert pd.api.types.is_numeric_dtype(df_clean['valor']), f'valor is not numeric! dtype={df_clean[\"valor\"].dtype}'\nassert pd.api.types.is_datetime64_any_dtype(df_clean['fecha']), 'fecha is not datetime!'\nassert df_clean['sexo'].isin(['Ambos sexos', 'Hombres', 'Mujeres']).all(), f'sexo has unexpected values: {df_clean[\"sexo\"].unique()}'\nprint('All validations passed.')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat = df_clean.copy()\n",
    "\n",
    "# 3.1) Temporal features\n",
    "df_feat['trimestre'] = df_feat['fecha'].dt.to_period('Q').astype('string')\n",
    "df_feat['mes'] = df_feat['fecha'].dt.month\n",
    "df_feat['year'] = df_feat['fecha'].dt.year\n",
    "\n",
    "# 3.2) Map periodo_id to quarter label\n",
    "periodo_map = {19: 'T4', 20: 'T1', 21: 'T2', 22: 'T3'}\n",
    "df_feat['trimestre_label'] = df_feat['periodo_id'].map(periodo_map).fillna('Otro')\n",
    "\n",
    "# 3.3) Classify table source\n",
    "tabla_map = {\n",
    "    65345: 'Poblacion',\n",
    "    65349: 'Tasas',\n",
    "    65354: 'Ocupados por sector',\n",
    "}\n",
    "df_feat['fuente'] = df_feat['tabla'].map(tabla_map)\n",
    "\n",
    "# 3.4) Flag national vs provincial\n",
    "df_feat['es_nacional'] = df_feat['provincia'].str.lower().str.contains('total nacional', na=False)\n",
    "\n",
    "# 3.5) Map provinces to Autonomous Communities (CCAA)\n",
    "ccaa_map = {\n",
    "    'Almería': 'Andalucía', 'Cádiz': 'Andalucía', 'Córdoba': 'Andalucía',\n",
    "    'Granada': 'Andalucía', 'Huelva': 'Andalucía', 'Jaén': 'Andalucía',\n",
    "    'Málaga': 'Andalucía', 'Sevilla': 'Andalucía',\n",
    "    'Huesca': 'Aragón', 'Teruel': 'Aragón', 'Zaragoza': 'Aragón',\n",
    "    'Asturias': 'Asturias',\n",
    "    'Balears, Illes': 'Illes Balears',\n",
    "    'Palmas, Las': 'Canarias', 'Santa Cruz de Tenerife': 'Canarias',\n",
    "    'Cantabria': 'Cantabria',\n",
    "    'Ávila': 'Castilla y León', 'Burgos': 'Castilla y León', 'León': 'Castilla y León',\n",
    "    'Palencia': 'Castilla y León', 'Salamanca': 'Castilla y León',\n",
    "    'Segovia': 'Castilla y León', 'Soria': 'Castilla y León',\n",
    "    'Valladolid': 'Castilla y León', 'Zamora': 'Castilla y León',\n",
    "    'Albacete': 'Castilla-La Mancha', 'Ciudad Real': 'Castilla-La Mancha',\n",
    "    'Cuenca': 'Castilla-La Mancha', 'Guadalajara': 'Castilla-La Mancha',\n",
    "    'Toledo': 'Castilla-La Mancha',\n",
    "    'Barcelona': 'Cataluña', 'Girona': 'Cataluña', 'Lleida': 'Cataluña',\n",
    "    'Tarragona': 'Cataluña',\n",
    "    'Alicante/Alacant': 'Comunitat Valenciana', 'Castellón/Castelló': 'Comunitat Valenciana',\n",
    "    'Valencia/València': 'Comunitat Valenciana',\n",
    "    'Badajoz': 'Extremadura', 'Cáceres': 'Extremadura',\n",
    "    'Coruña, A': 'Galicia', 'Lugo': 'Galicia', 'Ourense': 'Galicia',\n",
    "    'Pontevedra': 'Galicia',\n",
    "    'Madrid': 'Comunidad de Madrid',\n",
    "    'Murcia': 'Región de Murcia',\n",
    "    'Navarra': 'Navarra',\n",
    "    'Araba/Álava': 'País Vasco', 'Bizkaia': 'País Vasco', 'Gipuzkoa': 'País Vasco',\n",
    "    'Rioja, La': 'La Rioja',\n",
    "    'Ceuta': 'Ceuta', 'Melilla': 'Melilla',\n",
    "    'Total Nacional': 'Total Nacional',\n",
    "}\n",
    "df_feat['ccaa'] = df_feat['provincia'].map(ccaa_map).fillna('Desconocida')\n",
    "\n",
    "print(f'Shape with features: {df_feat.shape}')\n",
    "print(f'New columns: trimestre, mes, year, trimestre_label, fuente, es_nacional, ccaa')\n",
    "display(df_feat.head())\n",
    "print(f'\\nCCAA unique: {df_feat[\"ccaa\"].nunique()}')\n",
    "print(f'CCAA values:')\n",
    "display(df_feat['ccaa'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Derive the period from the data itself — used in all chart titles\nPERIOD_START = int(df_feat['anyo'].min())\nPERIOD_END = int(df_feat['anyo'].max())\nPERIOD_LABEL = f'{PERIOD_START}–{PERIOD_END}'\nprint(f'Data period: {PERIOD_LABEL}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Guardar datos procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "out_path = OUT_PATH\nout_path.parent.mkdir(parents=True, exist_ok=True)\ndf_feat.to_csv(out_path, index=False)\nprint(f'Saved: {out_path}')\nprint(f'Shape: {df_feat.shape}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Visualizaciones\n",
    "\n",
    "4-6 graficos con intencion: comparacion, distribucion, relacion, temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CHART 1: Tasa de paro por provincia (ultimo trimestre)\n",
    "# =====================================================\n",
    "\n",
    "# Filter: rates table, unemployment rate, both sexes, provincial (not national)\n",
    "df_tasas = df_feat[\n",
    "    (df_feat['tabla'] == 65349) &\n",
    "    (df_feat['actividad'].str.contains('paro', case=False, na=False)) &\n",
    "    (df_feat['sexo'] == 'Ambos sexos') &\n",
    "    (~df_feat['es_nacional'])\n",
    "].copy()\n",
    "\n",
    "# Get the most recent quarter\n",
    "ultimo_trimestre = df_tasas['trimestre'].dropna().max()\n",
    "df_ultimo = df_tasas[df_tasas['trimestre'] == ultimo_trimestre].dropna(subset=['valor']).copy()\n",
    "\n",
    "print(f'Ultimo trimestre: {ultimo_trimestre}')\n",
    "print(f'Provincias: {df_ultimo[\"provincia\"].nunique()}')\n",
    "\n",
    "# Sort by unemployment rate\n",
    "df_plot = df_ultimo.sort_values('valor', ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 14))\n",
    "median_val = df_plot['valor'].median()\n",
    "colors = ['#e74c3c' if v > median_val else '#2ecc71' for v in df_plot['valor'].values]\n",
    "ax.barh(df_plot['provincia'], df_plot['valor'], color=colors)\n",
    "ax.set_xlabel('Tasa de paro (%)')\n",
    "ax.set_title(f'Tasa de paro por provincia — {ultimo_trimestre} ({PERIOD_LABEL})\\n(rojo = por encima de la mediana)')\n",
    "ax.axvline(median_val, color='gray', linestyle='--', alpha=0.7, label='Mediana')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(CHARTS / '01_tasa_paro_por_provincia.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nTop 5 paro:\\n{df_plot.tail(5)[[\"provincia\", \"valor\"]].to_string(index=False)}')\n",
    "print(f'\\nBottom 5 paro:\\n{df_plot.head(5)[[\"provincia\", \"valor\"]].to_string(index=False)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CHART 2: Brecha de genero en tasa de paro (H vs M)\n",
    "# =====================================================\n",
    "\n",
    "df_genero = df_feat[\n",
    "    (df_feat['tabla'] == 65349) &\n",
    "    (df_feat['actividad'].str.contains('paro', case=False, na=False)) &\n",
    "    (df_feat['sexo'].isin(['Hombres', 'Mujeres'])) &\n",
    "    (df_feat['es_nacional'])\n",
    "].copy()\n",
    "\n",
    "df_genero = df_genero.sort_values('fecha')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "for sexo, color in [('Hombres', '#3498db'), ('Mujeres', '#e74c3c')]:\n",
    "    mask = df_genero['sexo'] == sexo\n",
    "    ax.plot(df_genero.loc[mask, 'fecha'], df_genero.loc[mask, 'valor'],\n",
    "            marker='o', label=sexo, color=color, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Fecha')\n",
    "ax.set_ylabel('Tasa de paro (%)')\n",
    "ax.set_title(f'Evolucion de la tasa de paro por sexo — Total Nacional ({PERIOD_LABEL})')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig.savefig(CHARTS / '02_brecha_genero_paro.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================\n# CHART 3: Empleo por sector economico (evolucion)\n# =====================================================\n\ndf_sector = df_feat[\n    (df_feat['tabla'] == 65354) &\n    (df_feat['es_nacional']) &\n    (~df_feat['actividad'].str.contains('Total', case=False, na=False))\n].copy()\n\n# Extract sector name from actividad\ndf_sector['sector'] = df_sector['actividad'].str.replace('Ocupados - ', '', regex=False)\ndf_sector = df_sector.sort_values('fecha')\n\nfig, ax = plt.subplots(figsize=(12, 5))\nsector_colors = {'Agricultura': '#27ae60', 'Industria': '#2980b9',\n                 'Construcción': '#f39c12', 'Servicios': '#8e44ad'}\nfor sector in df_sector['sector'].unique():\n    mask = df_sector['sector'] == sector\n    color = sector_colors.get(sector, 'gray')\n    ax.plot(df_sector.loc[mask, 'fecha'], df_sector.loc[mask, 'valor'], # type: ignore\n            marker='o', label=sector, color=color, linewidth=2)\n\nax.set_xlabel('Fecha')\nax.set_ylabel('Ocupados (miles de personas)')\nax.set_title(f'Evolucion del empleo por sector economico — Total Nacional ({PERIOD_LABEL})')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nfig.savefig(CHARTS / '03_empleo_por_sector.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================\n# CHART 4: Distribucion media de ocupados por provincia\n# =====================================================\n\ndf_ocup = df_feat[\n    (df_feat['tabla'] == 65345) &\n    (df_feat['actividad'].str.lower() == 'ocupados') &\n    (df_feat['sexo'] == 'Ambos sexos') &\n    (~df_feat['es_nacional'])\n].dropna(subset=['valor']).copy()\n\navg = df_ocup.groupby('provincia')['valor'].mean().sort_values(ascending=True)\n\nfig, ax = plt.subplots(figsize=(10, 14))\nmedian_val = avg.median()\ncolors = ['#2980b9' if v < median_val else '#e67e22' for v in avg.values]\nax.barh(avg.index, avg.values, color=colors)\nax.set_xlabel('Ocupados (miles, media del periodo)')\nax.set_title(f'Distribucion media de ocupados por provincia ({PERIOD_LABEL})')\nplt.tight_layout()\nfig.savefig(CHARTS / '04_distribucion_ocupados.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint('Altamente sesgada: la mayoria de provincias tienen poca poblacion,'\n      ' pero Madrid y Barcelona concentran el empleo.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================\n# CHART 5: Evolucion del empleo total (ocupados total nacional)\n# =====================================================\n\ndf_empleo = df_feat[\n    (df_feat['tabla'] == 65345) &\n    (df_feat['actividad'].str.lower() == 'ocupados') &\n    (df_feat['sexo'] == 'Ambos sexos') &\n    (df_feat['es_nacional'])\n].sort_values('fecha').copy()\n\nvmin, vmax = df_empleo['valor'].min(), df_empleo['valor'].max()\nbuffer = (vmax - vmin) * 0.10\ny_bottom = vmin - buffer\n\nfig, ax = plt.subplots(figsize=(12, 5))\nax.plot(df_empleo['fecha'], df_empleo['valor'], marker='o', color='#2c3e50', linewidth=2)\nax.fill_between(df_empleo['fecha'], df_empleo['valor'], y_bottom, alpha=0.15, color='#2c3e50')\nax.set_ylim(bottom=y_bottom)\n\nax.set_xlabel('Fecha')\nax.set_ylabel('Ocupados (miles de personas)')\nax.set_title(f'Evolucion del empleo total — Total Nacional ({PERIOD_LABEL})')\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nfig.savefig(CHARTS / '05_evolucion_empleo_total.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =====================================================\n# CHART 6: Heatmap — tasa de paro por CCAA y trimestre\n# =====================================================\n\n# Aggregate: mean unemployment rate by CCAA and trimestre\ndf_heat = df_feat[\n    (df_feat['tabla'] == 65349) &\n    (df_feat['actividad'].str.contains('paro', case=False, na=False)) &\n    (df_feat['sexo'] == 'Ambos sexos') &\n    (~df_feat['es_nacional']) &\n    (df_feat['ccaa'] != 'Desconocida')\n].dropna(subset=['valor']).copy()\n\n# Ensure valor is plain float (not nullable Float64)\ndf_heat['valor'] = df_heat['valor'].astype(float)\n\npivot = df_heat.pivot_table(values='valor', index='ccaa', columns='trimestre',\n                            aggfunc='mean')\n# Sort by mean across all quarters\npivot = pivot.loc[pivot.mean(axis=1).sort_values(ascending=False).index]\n\nfig, ax = plt.subplots(figsize=(14, 10))\nsns.heatmap(pivot, annot=False, cmap='RdYlGn_r', ax=ax,\n            linewidths=0.5, cbar_kws={'label': 'Tasa de paro (%)'})\nax.set_title(f'Tasa de paro media por CCAA y trimestre ({PERIOD_LABEL})')\nax.set_xlabel('Trimestre')\nax.set_ylabel('Comunidad Autonoma')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nfig.savefig(CHARTS / '06_heatmap_paro_ccaa.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6) Analisis adicional: Edad y Nacionalidad\n\nLos siguientes graficos utilizan las tablas adicionales descargadas por `fetch_data.py`:\n- Tabla 65219: Tasas de paro por sexo y grupo de edad\n- Tablas 65086 + 65112: Activos y ocupados por nacionalidad, sexo y grupo de edad (merge para calcular tasa de paro)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# CHART 7: Tasa de paro por grupo de edad y sexo\n",
    "# =====================================================\n",
    "\n",
    "json_path_edad = DATA_RAW / 'epa_tasas_paro_edad_raw.json'\n",
    "with open(json_path_edad, encoding='utf-8') as f:\n",
    "    edad_raw = json.load(f)\n",
    "\n",
    "# Parse series — structure: \"{loc/measure}. {measure/loc}. {sexo}. {edad}.\"\n",
    "rows_edad = []\n",
    "for serie in edad_raw:\n",
    "    parts = [p.strip() for p in serie['Nombre'].split('.') if p.strip()]\n",
    "    # sexo is always at index 2, edad at index 3\n",
    "    if len(parts) < 4:\n",
    "        continue\n",
    "    sexo = parts[2]\n",
    "    edad = parts[3]\n",
    "    for dp in serie.get('Data', []):\n",
    "        rows_edad.append({\n",
    "            'sexo': sexo, 'edad': edad,\n",
    "            'anyo': dp['Anyo'], 'periodo_id': dp['FK_Periodo'],\n",
    "            'valor': dp['Valor']\n",
    "        })\n",
    "\n",
    "df_edad = pd.DataFrame(rows_edad)\n",
    "print(f'Sexos: {df_edad[\"sexo\"].unique()}')\n",
    "print(f'Edades: {df_edad[\"edad\"].unique()}')\n",
    "\n",
    "# Total age group is \"16 y más años\", not \"Total\"\n",
    "total_age = [e for e in df_edad['edad'].unique() if '16 y m' in e.lower()]\n",
    "total_age_label = total_age[0] if total_age else None\n",
    "print(f'Total age label: {total_age_label}')\n",
    "\n",
    "# Use latest available quarter\n",
    "latest = df_edad.sort_values(['anyo', 'periodo_id'], ascending=False).iloc[0]\n",
    "latest_anyo, latest_per = int(latest['anyo']), int(latest['periodo_id'])\n",
    "periodo_map = {19: 'T4', 20: 'T1', 21: 'T2', 22: 'T3'}\n",
    "trim_label = f\"{periodo_map.get(latest_per, 'P' + str(latest_per))} {latest_anyo}\"\n",
    "\n",
    "df_e = df_edad[\n",
    "    (df_edad['anyo'] == latest_anyo) &\n",
    "    (df_edad['periodo_id'] == latest_per) &\n",
    "    (df_edad['edad'] != total_age_label)\n",
    "].copy()\n",
    "\n",
    "# Extract numeric start of age range for sorting\n",
    "df_e['age_start'] = df_e['edad'].str.extract(r'(\\d+)').astype(float)\n",
    "df_e = df_e.sort_values('age_start')\n",
    "age_labels = df_e['edad'].unique()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "x = np.arange(len(age_labels))\n",
    "width = 0.25\n",
    "for i, (sexo, color) in enumerate([\n",
    "    ('Ambos sexos', '#555555'), ('Hombres', '#3498db'), ('Mujeres', '#e74c3c')\n",
    "]):\n",
    "    mask = df_e['sexo'] == sexo\n",
    "    if mask.sum() == 0:\n",
    "        mask = df_e['sexo'].str.lower() == sexo.lower()\n",
    "    vals = df_e.loc[mask].set_index('edad').reindex(age_labels)['valor'].values\n",
    "    ax.bar(x + (i - 1) * width, vals, width, label=sexo, color=color, alpha=0.85)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "short_labels = [e.replace(' años', '').replace('De ', '').replace(' a ', '-')\n",
    "                .replace(' y más', '+') for e in age_labels]\n",
    "ax.set_xticklabels(short_labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Tasa de paro (%)')\n",
    "ax.set_xlabel('Grupo de edad')\n",
    "ax.set_title(f'Tasa de paro por grupo de edad y sexo — Total Nacional ({trim_label})')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "fig.savefig(CHARTS / '07_paro_por_edad.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# =====================================================\n# CHART 8: Evolucion del paro juvenil vs total\n# =====================================================\n\n# Ensure df_edad and total_age_label exist (load if necessary)\nif 'df_edad' not in globals():\n    json_path_edad = DATA_RAW / 'epa_tasas_paro_edad_raw.json'\n    with open(json_path_edad, encoding='utf-8') as f:\n        edad_raw = json.load(f)\n    rows_edad = []\n    for serie in edad_raw:\n        parts = [p.strip() for p in serie['Nombre'].split('.') if p.strip()]\n        if len(parts) < 4:\n            continue\n        sexo = parts[2]\n        edad = parts[3]\n        for dp in serie.get('Data', []):\n            rows_edad.append({\n                'sexo': sexo, 'edad': edad,\n                'anyo': dp['Anyo'], 'periodo_id': dp['FK_Periodo'],\n                'valor': dp['Valor']\n            })\n    df_edad = pd.DataFrame(rows_edad)\n\nif 'total_age_label' not in globals():\n    total_age = [e for e in df_edad['edad'].unique() if '16 y m' in e.lower()]\n    total_age_label = total_age[0] if total_age else None\n\nambos_mask = df_edad['sexo'].str.lower() == 'ambos sexos'\n\n# Identify the two youngest age groups dynamically (exclude the total \"16 y más\")\nnon_total_ages = [e for e in df_edad['edad'].unique() if e != total_age_label]\nage_groups_sorted = sorted(non_total_ages,\n                           key=lambda e: int(''.join(c for c in e if c.isdigit())[:2]) if any(c.isdigit() for c in e) else 999)\nyouth_groups = age_groups_sorted[:2]\n\nprint(f'Youth groups: {youth_groups}')\nprint(f'Total age: {total_age_label}')\n\ndf_juv = df_edad[ambos_mask & df_edad['edad'].isin(youth_groups + [total_age_label])].copy()\n\n# Build date from anyo + periodo_id\nq_to_month = {19: 12, 20: 3, 21: 6, 22: 9}\ndate_strs = [\n    f\"{int(row['anyo'])}-{q_to_month.get(int(row['periodo_id']), 1):02d}-01\"\n    for _, row in df_juv.iterrows()\n]\ndf_juv['fecha'] = pd.to_datetime(date_strs)\ndf_juv = df_juv.sort_values('fecha')\n\nfig, ax = plt.subplots(figsize=(14, 6))\ncolors = ['#e74c3c', '#f39c12', '#95a5a6']\n# use explicit (linestyle, marker) tuples to avoid passing a positional fmt arg\nstyles = [('-', 'o'), ('-', 'o'), ('--', 's')]\nfor (edad, color, (linestyle, marker)) in zip(youth_groups + [total_age_label], colors, styles):\n    mask = df_juv['edad'] == edad\n    label = edad.replace(' años', '').replace('De ', '').replace(' a ', '-').replace(' y más', '+')\n    if edad == total_age_label:\n        label = f'Total ({label})'\n    # Use numpy.asarray to avoid static type-checker issues with Series.to_numpy on mixed types\n    x = np.asarray(df_juv.loc[mask, 'fecha'])\n    y = np.asarray(df_juv.loc[mask, 'valor'])\n    ax.plot(x, y, linestyle=linestyle, marker=marker, label=label, color=color, linewidth=2, markersize=6)\n\nax.set_xlabel('Fecha')\nax.set_ylabel('Tasa de paro (%)')\nax.set_title(f'Evolucion del paro juvenil vs total — Total Nacional ({PERIOD_LABEL})')\nax.legend(fontsize=11)\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nfig.savefig(CHARTS / '08_paro_juvenil_evolucion.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# =====================================================\n# CHART 9: Tasa de paro por edad y nacionalidad\n# =====================================================\n# Computed from two tables: 65086 (activos) and 65112 (ocupados)\n# tasa_paro = (activos - ocupados) / activos * 100\n\ndef load_nationality_table(json_path, measure_name):\n    with open(json_path, encoding='utf-8') as f:\n        raw = json.load(f)\n    rows = []\n    for serie in raw:\n        parts = [p.strip() for p in serie['Nombre'].split('.') if p.strip()]\n        if len(parts) < 6:\n            continue\n        sexo, edad, nacionalidad = parts[2], parts[3], parts[4]\n        for dp in serie.get('Data', []):\n            rows.append({\n                'sexo': sexo, 'edad': edad, 'nacionalidad': nacionalidad,\n                'anyo': dp['Anyo'], 'periodo_id': dp['FK_Periodo'],\n                'valor': dp['Valor']\n            })\n    return pd.DataFrame(rows)\n\nactivos_path = DATA_RAW / 'epa_activos_nacionalidad_edad_raw.json'\nocupados_path = DATA_RAW / 'epa_ocupados_nacionalidad_edad_raw.json'\n\ndf_act = load_nationality_table(activos_path, 'activos')\ndf_ocu = load_nationality_table(ocupados_path, 'ocupados')\n\n# Merge and compute unemployment rate\nmerge_keys = ['sexo', 'edad', 'nacionalidad', 'anyo', 'periodo_id']\ndf_merge = (\n    df_act[merge_keys + ['valor']].rename(columns={'valor': 'activos'})\n    .merge(df_ocu[merge_keys + ['valor']].rename(columns={'valor': 'ocupados'}),\n           on=merge_keys, how='inner')\n)\ndf_merge['tasa_paro'] = (df_merge['activos'] - df_merge['ocupados']) / df_merge['activos'] * 100\n\n# Latest quarter, both sexes, exclude total age, Spanish vs Foreign\nlatest = df_merge.sort_values(['anyo', 'periodo_id'], ascending=False).iloc[0]\nlat_anyo, lat_per = int(latest['anyo']), int(latest['periodo_id'])\ntrim9 = f\"{periodo_map.get(lat_per, 'P' + str(lat_per))} {lat_anyo}\"\n\n# Find the 'total' age group (contains '16 y m' or similar)\ntotal_edad = [e for e in df_merge['edad'].unique() if '16 y m' in e.lower()]\ntotal_edad_val = total_edad[0] if total_edad else None\n\ndf_c9 = df_merge[\n    (df_merge['anyo'] == lat_anyo) &\n    (df_merge['periodo_id'] == lat_per) &\n    (df_merge['sexo'].str.lower() == 'ambos sexos') &\n    (df_merge['edad'] != total_edad_val) &\n    (df_merge['nacionalidad'].isin(['Española', 'Extranjera: Total']))\n].copy()\n\n# Sort age groups\ndf_c9['age_start'] = df_c9['edad'].str.extract(r'(\\d+)').astype(float)\ndf_c9 = df_c9.sort_values('age_start')\nage_order = df_c9['edad'].unique()\n\nfig, ax = plt.subplots(figsize=(12, 7))\nx = np.arange(len(age_order))\nwidth = 0.35\n\nesp = df_c9[df_c9['nacionalidad'] == 'Española'].set_index('edad').reindex(age_order)\next = df_c9[df_c9['nacionalidad'] == 'Extranjera: Total'].set_index('edad').reindex(age_order)\n\nbars1 = ax.bar(x - width/2, esp['tasa_paro'].values, width, label='Española', color='#2196F3', alpha=0.85)\nbars2 = ax.bar(x + width/2, ext['tasa_paro'].values, width, label='Extranjera', color='#FF9800', alpha=0.85)\n\nfor bar in list(bars1) + list(bars2):\n    h = bar.get_height()\n    if not np.isnan(h):\n        ax.text(bar.get_x() + bar.get_width()/2, h + 0.3, f'{h:.1f}%', ha='center', va='bottom', fontsize=9)\n\nshort_age = [e.replace(' años', '').replace('De ', '').replace(' a ', '-')\n             .replace(' y más', '+') for e in age_order]\nax.set_xticks(x)\nax.set_xticklabels(short_age, fontsize=12)\nax.set_title(f'Tasa de paro por grupo de edad y nacionalidad — {trim9}')\nax.set_xlabel('Grupo de edad')\nax.set_ylabel('Tasa de paro (%)')\nax.legend(fontsize=11, loc='upper right')\nax.yaxis.set_major_formatter(mticker.FuncFormatter(lambda v, _: f'{v:.0f}%'))\nplt.tight_layout()\nfig.savefig(CHARTS / '09_paro_edad_nacionalidad.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f'\\nDatos del grafico ({trim9}):')\nprint(df_c9[['edad', 'nacionalidad', 'tasa_paro']].to_string(index=False))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7) Conclusiones\n\n1. **Fuerte desigualdad territorial:** Las provincias del sur (Andalucía, Extremadura, Canarias) mantienen tasas de paro significativamente más altas que las del norte (País Vasco, Navarra, Aragón). Esta brecha se ha mantenido estable a lo largo del periodo analizado. (ver gráfico 1 y 6)\n\n2. **Brecha de género persistente pero reduciéndose:** La tasa de paro femenina es consistentemente más alta que la masculina, aunque la diferencia se ha ido estrechando. (ver gráfico 2)\n\n3. **Economía terciarizada:** El sector servicios domina abrumadoramente el empleo (>75%), con agricultura, industria y construcción en niveles relativamente estables. (ver gráfico 3)\n\n4. **Evolución del empleo total:** El gráfico 5 muestra la trayectoria del empleo total a lo largo del periodo, incluyendo eventos significativos que hayan afectado al mercado laboral. (ver gráfico 5)\n\n5. **Concentración del empleo:** La distribución de empleo por provincia está altamente sesgada — Madrid y Barcelona concentran una proporción desproporcionada, mientras la mayoría de provincias tienen poblaciones ocupadas relativamente pequeñas. (ver gráfico 4)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}